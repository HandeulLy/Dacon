{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>QeE</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>363</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1370</td>\n",
       "      <td>5.0</td>\n",
       "      <td>997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>647</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1313</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4320</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>357</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>707</td>\n",
       "      <td>5.0</td>\n",
       "      <td>556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45527</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>5.0</td>\n",
       "      <td>619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>602</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45528</th>\n",
       "      <td>2.0</td>\n",
       "      <td>581</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1353</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1680</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45529</th>\n",
       "      <td>4.0</td>\n",
       "      <td>593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1515</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1690</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45530</th>\n",
       "      <td>1.0</td>\n",
       "      <td>747</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>892</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1328</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45531</th>\n",
       "      <td>3.0</td>\n",
       "      <td>496</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1827</td>\n",
       "      <td>5.0</td>\n",
       "      <td>754</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>432</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45532 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA   QeE  ...  wr_04  \\\n",
       "index                                                         ...          \n",
       "0      3.0   363  4.0  1370  5.0   997  1.0  1024  2.0  1577  ...      0   \n",
       "1      5.0   647  5.0  1313  3.0  3387  5.0  2969  1.0  4320  ...      1   \n",
       "2      4.0  1623  1.0  1480  1.0  1021  4.0  3374  5.0  1333  ...      1   \n",
       "3      3.0   504  3.0  2311  4.0   992  3.0  3245  1.0   357  ...      0   \n",
       "4      1.0   927  1.0   707  5.0   556  2.0  1062  1.0  1014  ...      1   \n",
       "...    ...   ...  ...   ...  ...   ...  ...   ...  ...   ...  ...    ...   \n",
       "45527  2.0  1050  5.0   619  4.0   328  1.0   285  1.0   602  ...      1   \n",
       "45528  2.0   581  3.0  1353  4.0  1164  1.0   798  3.0  1680  ...      1   \n",
       "45529  4.0   593  1.0   857  1.0  1047  4.0  1515  5.0  1690  ...      1   \n",
       "45530  1.0   747  3.0  1331  4.0   892  2.0  1281  1.0  1328  ...      1   \n",
       "45531  3.0   496  5.0  1827  5.0   754  3.0  1117  1.0   432  ...      1   \n",
       "\n",
       "       wr_05  wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "index                                                                 \n",
       "0          1      0      1      1      0      1      0      1      1  \n",
       "1          1      0      1      1      0      1      0      1      1  \n",
       "2          1      0      1      1      1      1      0      1      1  \n",
       "3          0      0      0      1      0      1      0      1      1  \n",
       "4          1      1      1      1      0      1      1      1      1  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "45527      1      0      1      1      1      1      0      1      1  \n",
       "45528      1      0      1      1      1      1      0      1      1  \n",
       "45529      1      0      1      1      0      1      0      1      1  \n",
       "45530      1      0      1      1      1      1      0      1      1  \n",
       "45531      1      0      1      1      0      1      0      1      1  \n",
       "\n",
       "[45532 rows x 77 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('data/train.csv', index_col=0)\n",
    "test=pd.read_csv('data/test_x.csv', index_col=0)\n",
    "submission=pd.read_csv('data/sample_submission.csv', index_col=0)  \n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('voted', axis = 1)\n",
    "y = train['voted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. 데이터 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White                    31248\n",
      "Asian                     6834\n",
      "Other                     4330\n",
      "Black                     2168\n",
      "Native American            548\n",
      "Arab                       351\n",
      "Indigenous Australian       53\n",
      "Name: race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.race.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10s     14215\n",
      "20s     14112\n",
      "30s      7836\n",
      "40s      5051\n",
      "50s      2889\n",
      "60s      1194\n",
      "+70s      235\n",
      "Name: age_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.age_group.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male      24217\n",
      "Female    21315\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.gender.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atheist                 10192\n",
      "Agnostic                 9624\n",
      "Christian_Catholic       6431\n",
      "Christian_Other          5137\n",
      "Christian_Protestant     4875\n",
      "Other                    4770\n",
      "Hindu                    1429\n",
      "Muslim                   1192\n",
      "Buddhist                  850\n",
      "Jewish                    487\n",
      "Christian_Mormon          428\n",
      "Sikh                      117\n",
      "Name: religion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.religion.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 칼럼 :  ['QaA', 'QaE', 'QbA', 'QbE', 'QcA', 'QcE', 'QdA', 'QdE', 'QeA', 'QeE', 'QfA', 'QfE', 'QgA', 'QgE', 'QhA', 'QhE', 'QiA', 'QiE', 'QjA', 'QjE', 'QkA', 'QkE', 'QlA', 'QlE', 'QmA', 'QmE', 'QnA', 'QnE', 'QoA', 'QoE', 'QpA', 'QpE', 'QqA', 'QqE', 'QrA', 'QrE', 'QsA', 'QsE', 'QtA', 'QtE', 'age_group', 'education', 'engnat', 'familysize', 'gender', 'hand', 'married', 'race', 'religion', 'tp01', 'tp02', 'tp03', 'tp04', 'tp05', 'tp06', 'tp07', 'tp08', 'tp09', 'tp10', 'urban', 'wf_01', 'wf_02', 'wf_03', 'wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05', 'wr_06', 'wr_07', 'wr_08', 'wr_09', 'wr_10', 'wr_11', 'wr_12', 'wr_13'] \n",
      "\n",
      "get_dummies된 데이터 칼럼 :  ['QaA', 'QaE', 'QbA', 'QbE', 'QcA', 'QcE', 'QdA', 'QdE', 'QeA', 'QeE', 'QfA', 'QfE', 'QgA', 'QgE', 'QhA', 'QhE', 'QiA', 'QiE', 'QjA', 'QjE', 'QkA', 'QkE', 'QlA', 'QlE', 'QmA', 'QmE', 'QnA', 'QnE', 'QoA', 'QoE', 'QpA', 'QpE', 'QqA', 'QqE', 'QrA', 'QrE', 'QsA', 'QsE', 'QtA', 'QtE', 'education', 'engnat', 'familysize', 'hand', 'married', 'tp01', 'tp02', 'tp03', 'tp04', 'tp05', 'tp06', 'tp07', 'tp08', 'tp09', 'tp10', 'urban', 'wf_01', 'wf_02', 'wf_03', 'wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05', 'wr_06', 'wr_07', 'wr_08', 'wr_09', 'wr_10', 'wr_11', 'wr_12', 'wr_13', 'age_group_+70s', 'age_group_10s', 'age_group_20s', 'age_group_30s', 'age_group_40s', 'age_group_50s', 'age_group_60s', 'gender_Female', 'gender_Male', 'race_Arab', 'race_Asian', 'race_Black', 'race_Indigenous Australian', 'race_Native American', 'race_Other', 'race_White', 'religion_Agnostic', 'religion_Atheist', 'religion_Buddhist', 'religion_Christian_Catholic', 'religion_Christian_Mormon', 'religion_Christian_Other', 'religion_Christian_Protestant', 'religion_Hindu', 'religion_Jewish', 'religion_Muslim', 'religion_Other', 'religion_Sikh']\n"
     ]
    }
   ],
   "source": [
    "print(\"원본 데이터 칼럼 : \", list(X.columns), \"\\n\")\n",
    "X_dummies = pd.get_dummies(X)\n",
    "\n",
    "print(\"get_dummies된 데이터 칼럼 : \", list(X_dummies.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (45532, 76)\tX_dummies: (45532, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"X: {}\\tX_dummies: {}\".format(X.shape, X_dummies.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11383, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.get_dummies(test)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dummies : (45532, 100)\n",
      "test : (11383, 100)\n",
      "Encoding Success\n"
     ]
    }
   ],
   "source": [
    "# 칼럼 개수 변화\n",
    "print(\"X_dummies : {}\\ntest : {}\".format(X_dummies.shape, test.shape))\n",
    "\n",
    "# 인코딩 확인\n",
    "print(\"Encoding Success\") if list(X_dummies.columns) == list(test.columns) else list(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45532, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nan 값 메꾸기\n",
    "X = X_dummies.fillna(X_dummies.mean())\n",
    "\n",
    "# 중복 값 제거\n",
    "X.drop_duplicates(keep='first', inplace = True)\n",
    "\n",
    "# 비교 -> nan 없음\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.00000000e-01, 1.40020340e-04, 7.50000000e-01, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.57670567e-04, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.50000000e-01, 6.61989656e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [7.50000000e-01, 2.35300453e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 2.99096703e-04, 5.00000000e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.00000000e-01, 1.95117101e-04, 1.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 데이터 스케일링 -> 민맥스/스텐다드 모두 성능 비슷함\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "# 테스트 데이터도 동일 스케일러로\n",
    "test=scaler.transform(test)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_cv(learning_rate, num_leaves, max_depth, min_child_weight, colsample_bytree, feature_fraction, bagging_fraction, lambda_l1, lambda_l2):\n",
    "    model = lgbm.LGBMClassifier(learning_rate=learning_rate,\n",
    "                                n_estimators = 300,\n",
    "                                #boosting = 'dart',\n",
    "                                num_leaves = int(round(num_leaves)),\n",
    "                                max_depth = int(round(max_depth)),\n",
    "                                min_child_weight = int(round(min_child_weight)),\n",
    "                                colsample_bytree = colsample_bytree,\n",
    "                                feature_fraction = max(min(feature_fraction, 1), 0),\n",
    "                                bagging_fraction = max(min(bagging_fraction, 1), 0),\n",
    "                                lambda_l1 = max(lambda_l1, 0),\n",
    "                                lambda_l2 = max(lambda_l2, 0)\n",
    "                               )\n",
    "    scoring = {'roc_auc_score': make_scorer(roc_auc_score)}\n",
    "    result = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "    auc_score = result[\"test_roc_auc_score\"].mean()\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {'learning_rate' : (0.0001, 0.05),\n",
    "           'num_leaves': (300, 600),\n",
    "           'max_depth': (2, 25),\n",
    "           'min_child_weight': (30, 100),\n",
    "           'colsample_bytree': (0, 0.99),\n",
    "           'feature_fraction': (0.0001, 0.99),\n",
    "           'bagging_fraction': (0.0001, 0.99),\n",
    "           'lambda_l1' : (0, 0.99),\n",
    "           'lambda_l2' : (0, 0.99),\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmBO = BayesianOptimization(f = lgbm_cv, pbounds = pbounds, verbose = 2, random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | colsam... | featur... | lambda_l1 | lambda_l2 | learni... | max_depth | min_ch... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6986  \u001b[0m | \u001b[0m 0.5434  \u001b[0m | \u001b[0m 0.708   \u001b[0m | \u001b[0m 0.5968  \u001b[0m | \u001b[0m 0.5394  \u001b[0m | \u001b[0m 0.4194  \u001b[0m | \u001b[0m 0.03233 \u001b[0m | \u001b[0m 12.06   \u001b[0m | \u001b[0m 92.42   \u001b[0m | \u001b[0m 589.1   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6865  \u001b[0m | \u001b[0m 0.3797  \u001b[0m | \u001b[0m 0.7838  \u001b[0m | \u001b[0m 0.5237  \u001b[0m | \u001b[0m 0.5624  \u001b[0m | \u001b[0m 0.9163  \u001b[0m | \u001b[0m 0.003645\u001b[0m | \u001b[0m 4.004   \u001b[0m | \u001b[0m 31.42   \u001b[0m | \u001b[0m 549.8   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7     \u001b[0m | \u001b[95m 0.7704  \u001b[0m | \u001b[95m 0.8613  \u001b[0m | \u001b[95m 0.9688  \u001b[0m | \u001b[95m 0.7912  \u001b[0m | \u001b[95m 0.4569  \u001b[0m | \u001b[95m 0.03905 \u001b[0m | \u001b[95m 4.72    \u001b[0m | \u001b[95m 74.79   \u001b[0m | \u001b[95m 343.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6999  \u001b[0m | \u001b[0m 0.9352  \u001b[0m | \u001b[0m 0.5166  \u001b[0m | \u001b[0m 0.4106  \u001b[0m | \u001b[0m 0.2619  \u001b[0m | \u001b[0m 0.7665  \u001b[0m | \u001b[0m 0.02286 \u001b[0m | \u001b[0m 15.07   \u001b[0m | \u001b[0m 31.32   \u001b[0m | \u001b[0m 485.3   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6978  \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 0.6108  \u001b[0m | \u001b[0m 0.9343  \u001b[0m | \u001b[0m 0.675   \u001b[0m | \u001b[0m 0.3559  \u001b[0m | \u001b[0m 0.02191 \u001b[0m | \u001b[0m 18.05   \u001b[0m | \u001b[0m 34.22   \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6994  \u001b[0m | \u001b[0m 0.5384  \u001b[0m | \u001b[0m 0.04871 \u001b[0m | \u001b[0m 0.3478  \u001b[0m | \u001b[0m 0.1378  \u001b[0m | \u001b[0m 0.9633  \u001b[0m | \u001b[0m 0.0238  \u001b[0m | \u001b[0m 22.71   \u001b[0m | \u001b[0m 57.85   \u001b[0m | \u001b[0m 442.4   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7003  \u001b[0m | \u001b[95m 0.615   \u001b[0m | \u001b[95m 0.2842  \u001b[0m | \u001b[95m 0.4637  \u001b[0m | \u001b[95m 0.7906  \u001b[0m | \u001b[95m 0.5104  \u001b[0m | \u001b[95m 0.04883 \u001b[0m | \u001b[95m 3.632   \u001b[0m | \u001b[95m 30.24   \u001b[0m | \u001b[95m 382.4   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6543  \u001b[0m | \u001b[0m 0.686   \u001b[0m | \u001b[0m 0.9669  \u001b[0m | \u001b[0m 0.01047 \u001b[0m | \u001b[0m 0.1853  \u001b[0m | \u001b[0m 0.2557  \u001b[0m | \u001b[0m 0.03188 \u001b[0m | \u001b[0m 24.52   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 315.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6977  \u001b[0m | \u001b[0m 0.5413  \u001b[0m | \u001b[0m 0.8265  \u001b[0m | \u001b[0m 0.2976  \u001b[0m | \u001b[0m 0.03282 \u001b[0m | \u001b[0m 0.2123  \u001b[0m | \u001b[0m 0.03936 \u001b[0m | \u001b[0m 2.633   \u001b[0m | \u001b[0m 70.79   \u001b[0m | \u001b[0m 384.3   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6983  \u001b[0m | \u001b[0m 0.6941  \u001b[0m | \u001b[0m 0.3692  \u001b[0m | \u001b[0m 0.3581  \u001b[0m | \u001b[0m 0.4821  \u001b[0m | \u001b[0m 0.6529  \u001b[0m | \u001b[0m 0.01721 \u001b[0m | \u001b[0m 4.418   \u001b[0m | \u001b[0m 30.27   \u001b[0m | \u001b[0m 422.1   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.683   \u001b[0m | \u001b[0m 0.7734  \u001b[0m | \u001b[0m 0.4754  \u001b[0m | \u001b[0m 0.05079 \u001b[0m | \u001b[0m 0.4677  \u001b[0m | \u001b[0m 0.4786  \u001b[0m | \u001b[0m 0.0293  \u001b[0m | \u001b[0m 2.596   \u001b[0m | \u001b[0m 31.73   \u001b[0m | \u001b[0m 383.5   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6961  \u001b[0m | \u001b[0m 0.8518  \u001b[0m | \u001b[0m 0.4633  \u001b[0m | \u001b[0m 0.3379  \u001b[0m | \u001b[0m 0.6867  \u001b[0m | \u001b[0m 0.06141 \u001b[0m | \u001b[0m 0.04023 \u001b[0m | \u001b[0m 12.76   \u001b[0m | \u001b[0m 91.87   \u001b[0m | \u001b[0m 545.5   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6994  \u001b[0m | \u001b[0m 0.9603  \u001b[0m | \u001b[0m 0.003919\u001b[0m | \u001b[0m 0.4968  \u001b[0m | \u001b[0m 0.1905  \u001b[0m | \u001b[0m 0.3403  \u001b[0m | \u001b[0m 0.02221 \u001b[0m | \u001b[0m 14.29   \u001b[0m | \u001b[0m 31.24   \u001b[0m | \u001b[0m 485.8   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6991  \u001b[0m | \u001b[0m 0.3036  \u001b[0m | \u001b[0m 0.06767 \u001b[0m | \u001b[0m 0.4564  \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 0.5681  \u001b[0m | \u001b[0m 0.0316  \u001b[0m | \u001b[0m 5.087   \u001b[0m | \u001b[0m 72.1    \u001b[0m | \u001b[0m 343.6   \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 0.701   \u001b[0m | \u001b[95m 0.159   \u001b[0m | \u001b[95m 0.2529  \u001b[0m | \u001b[95m 0.7675  \u001b[0m | \u001b[95m 0.7801  \u001b[0m | \u001b[95m 0.6409  \u001b[0m | \u001b[95m 0.02265 \u001b[0m | \u001b[95m 8.193   \u001b[0m | \u001b[95m 30.48   \u001b[0m | \u001b[95m 380.3   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6995  \u001b[0m | \u001b[0m 0.7101  \u001b[0m | \u001b[0m 0.2929  \u001b[0m | \u001b[0m 0.7939  \u001b[0m | \u001b[0m 0.481   \u001b[0m | \u001b[0m 0.2528  \u001b[0m | \u001b[0m 0.0371  \u001b[0m | \u001b[0m 6.158   \u001b[0m | \u001b[0m 30.51   \u001b[0m | \u001b[0m 382.0   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6792  \u001b[0m | \u001b[0m 0.7479  \u001b[0m | \u001b[0m 0.3636  \u001b[0m | \u001b[0m 0.888   \u001b[0m | \u001b[0m 0.009658\u001b[0m | \u001b[0m 0.9869  \u001b[0m | \u001b[0m 0.00187 \u001b[0m | \u001b[0m 7.997   \u001b[0m | \u001b[0m 76.45   \u001b[0m | \u001b[0m 346.3   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.694   \u001b[0m | \u001b[0m 0.119   \u001b[0m | \u001b[0m 0.4861  \u001b[0m | \u001b[0m 0.1017  \u001b[0m | \u001b[0m 0.8208  \u001b[0m | \u001b[0m 0.01521 \u001b[0m | \u001b[0m 0.03531 \u001b[0m | \u001b[0m 5.709   \u001b[0m | \u001b[0m 30.5    \u001b[0m | \u001b[0m 376.8   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6676  \u001b[0m | \u001b[0m 0.8015  \u001b[0m | \u001b[0m 0.234   \u001b[0m | \u001b[0m 0.01009 \u001b[0m | \u001b[0m 0.2333  \u001b[0m | \u001b[0m 0.1733  \u001b[0m | \u001b[0m 0.04348 \u001b[0m | \u001b[0m 2.493   \u001b[0m | \u001b[0m 73.36   \u001b[0m | \u001b[0m 341.4   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6985  \u001b[0m | \u001b[0m 0.1058  \u001b[0m | \u001b[0m 0.7954  \u001b[0m | \u001b[0m 0.2442  \u001b[0m | \u001b[0m 0.05641 \u001b[0m | \u001b[0m 0.74    \u001b[0m | \u001b[0m 0.03221 \u001b[0m | \u001b[0m 8.176   \u001b[0m | \u001b[0m 31.4    \u001b[0m | \u001b[0m 381.6   \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 0.7043  \u001b[0m | \u001b[95m 0.9516  \u001b[0m | \u001b[95m 0.786   \u001b[0m | \u001b[95m 0.9362  \u001b[0m | \u001b[95m 0.7111  \u001b[0m | \u001b[95m 0.5643  \u001b[0m | \u001b[95m 0.01141 \u001b[0m | \u001b[95m 6.09    \u001b[0m | \u001b[95m 33.33   \u001b[0m | \u001b[95m 380.2   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.9625  \u001b[0m | \u001b[0m 0.4699  \u001b[0m | \u001b[0m 0.8483  \u001b[0m | \u001b[0m 0.598   \u001b[0m | \u001b[0m 0.06879 \u001b[0m | \u001b[0m 0.02233 \u001b[0m | \u001b[0m 6.539   \u001b[0m | \u001b[0m 35.06   \u001b[0m | \u001b[0m 379.3   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6949  \u001b[0m | \u001b[0m 0.03632 \u001b[0m | \u001b[0m 0.1783  \u001b[0m | \u001b[0m 0.4311  \u001b[0m | \u001b[0m 0.04416 \u001b[0m | \u001b[0m 0.3632  \u001b[0m | \u001b[0m 0.005125\u001b[0m | \u001b[0m 6.761   \u001b[0m | \u001b[0m 32.44   \u001b[0m | \u001b[0m 378.9   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7007  \u001b[0m | \u001b[0m 0.4155  \u001b[0m | \u001b[0m 0.2127  \u001b[0m | \u001b[0m 0.6469  \u001b[0m | \u001b[0m 0.8476  \u001b[0m | \u001b[0m 0.9304  \u001b[0m | \u001b[0m 0.02003 \u001b[0m | \u001b[0m 6.782   \u001b[0m | \u001b[0m 33.45   \u001b[0m | \u001b[0m 382.1   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6987  \u001b[0m | \u001b[0m 0.3296  \u001b[0m | \u001b[0m 0.6078  \u001b[0m | \u001b[0m 0.9726  \u001b[0m | \u001b[0m 0.005871\u001b[0m | \u001b[0m 0.1608  \u001b[0m | \u001b[0m 0.004235\u001b[0m | \u001b[0m 7.953   \u001b[0m | \u001b[0m 37.69   \u001b[0m | \u001b[0m 381.7   \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbmBO.maximize(init_points=5, n_iter = 20, acq='ei', xi=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.7042782365476333,\n",
       " 'params': {'bagging_fraction': 0.9515683153667026,\n",
       "  'colsample_bytree': 0.7860120233288207,\n",
       "  'feature_fraction': 0.9362075859090412,\n",
       "  'lambda_l1': 0.7111030183072032,\n",
       "  'lambda_l2': 0.5642765168754059,\n",
       "  'learning_rate': 0.011407920284082697,\n",
       "  'max_depth': 6.090247578634,\n",
       "  'min_child_weight': 33.33272426081254,\n",
       "  'num_leaves': 380.181539974917}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmBO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_lgbm = lgbm.LGBMClassifier(learning_rate=lgbmBO.max['params']['learning_rate'],\n",
    "                               num_leaves = int(round(lgbmBO.max['params']['num_leaves'])),\n",
    "                               max_depth = int(round(lgbmBO.max['params']['max_depth'])),\n",
    "                               min_child_weight = int(round(lgbmBO.max['params']['min_child_weight'])),\n",
    "                               colsample_bytree=lgbmBO.max['params']['colsample_bytree'],\n",
    "                               feature_fraction = max(min(lgbmBO.max['params']['feature_fraction'], 1), 0),\n",
    "                               bagging_fraction = max(min(lgbmBO.max['params']['bagging_fraction'], 1), 0),\n",
    "                               lambda_l1 = lgbmBO.max['params']['lambda_l1'],\n",
    "                               lambda_l2 = lgbmBO.max['params']['lambda_l2']\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_lgbm.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['voted']=pred_y\n",
    "submission.to_csv('HDLY_201112_03.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
